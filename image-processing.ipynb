{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import Libraries","metadata":{"execution":{"iopub.status.busy":"2023-10-12T20:09:42.126505Z","iopub.execute_input":"2023-10-12T20:09:42.126930Z","iopub.status.idle":"2023-10-12T20:09:42.134485Z","shell.execute_reply.started":"2023-10-12T20:09:42.126900Z","shell.execute_reply":"2023-10-12T20:09:42.133466Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-12T20:09:42.136044Z","iopub.execute_input":"2023-10-12T20:09:42.137204Z","iopub.status.idle":"2023-10-12T20:09:46.085288Z","shell.execute_reply.started":"2023-10-12T20:09:42.137143Z","shell.execute_reply":"2023-10-12T20:09:46.083544Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Get Dataset ","metadata":{}},{"cell_type":"code","source":"dataset_path = '/kaggle/input/cifar-10/sampleSubmission.csv'\ndata = pd.read_csv(dataset_path)\nprint(data.head())\n\n# You need to provide the actual path to the dataset files\ndataset_directory = '/kaggle/input/cifar-10/dataset/'  # Update this path","metadata":{"execution":{"iopub.status.busy":"2023-10-12T20:09:46.086706Z","iopub.execute_input":"2023-10-12T20:09:46.087975Z","iopub.status.idle":"2023-10-12T20:09:46.179990Z","shell.execute_reply.started":"2023-10-12T20:09:46.087876Z","shell.execute_reply":"2023-10-12T20:09:46.178747Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"   id label\n0   1   cat\n1   2   cat\n2   3   cat\n3   4   cat\n4   5   cat\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#  Split Data","metadata":{}},{"cell_type":"code","source":"# Split the data into features (X) and labels (Y)\nX = data['id']\nY = data['label']\n\n# Split data for trainging and testing purpose\ntrain_images, test_images, train_labels, test_labels = train_test_split(X, Y, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-12T20:09:46.182062Z","iopub.execute_input":"2023-10-12T20:09:46.183389Z","iopub.status.idle":"2023-10-12T20:09:46.235368Z","shell.execute_reply.started":"2023-10-12T20:09:46.183350Z","shell.execute_reply":"2023-10-12T20:09:46.233543Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Model Architecture","metadata":{}},{"cell_type":"code","source":"# Define the CNN model\nmodel = models.Sequential()\n\n# Convolutional and Pooling layers\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\n# Flatten layer\nmodel.add(layers.Flatten())\n\n# Fully connected layers\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dense(10, activation='softmax'))  # Assuming 10 classes\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Print a summary of the model architecture\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-12T20:09:46.236919Z","iopub.execute_input":"2023-10-12T20:09:46.237368Z","iopub.status.idle":"2023-10-12T20:09:46.752565Z","shell.execute_reply.started":"2023-10-12T20:09:46.237327Z","shell.execute_reply":"2023-10-12T20:09:46.751205Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 30, 30, 32)        896       \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n 2D)                                                             \n                                                                 \n conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n                                                                 \n max_pooling2d_2 (MaxPooling  (None, 2, 2, 128)        0         \n 2D)                                                             \n                                                                 \n flatten (Flatten)           (None, 512)               0         \n                                                                 \n dense (Dense)               (None, 128)               65664     \n                                                                 \n dense_1 (Dense)             (None, 10)                1290      \n                                                                 \n=================================================================\nTotal params: 160,202\nTrainable params: 160,202\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a dictionary to map class names to integer labels\nclass_to_label = {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4,\n                  'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}              # This dictionary class_to_label is used to map class names (such as 'airplane', 'automobile', etc.) to their corresponding integer labels. This mapping is essential for training machine learning models, as models require labels in numeric format.\n\n# Convert label names to integer labels\ntrain_labels_int = [class_to_label[label] for label in train_labels]\ntest_labels_int = [class_to_label[label] for label in test_labels]\n\n# Convert labels to one-hot encoded vectors\nnum_classes = 10  # Replace with the actual number of classes\ntrain_labels_encoded = tf.keras.utils.to_categorical(train_labels_int, num_classes=num_classes)\ntest_labels_encoded = tf.keras.utils.to_categorical(test_labels_int, num_classes=num_classes)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T20:09:46.754104Z","iopub.execute_input":"2023-10-12T20:09:46.754434Z","iopub.status.idle":"2023-10-12T20:09:46.846557Z","shell.execute_reply.started":"2023-10-12T20:09:46.754408Z","shell.execute_reply":"2023-10-12T20:09:46.845081Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess the Data","metadata":{}},{"cell_type":"code","source":"def preprocess_image(image_path, label):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.resize(image, (32, 32))  # Resize to your desired dimensions\n    return image, label","metadata":{"execution":{"iopub.status.busy":"2023-10-12T20:09:46.848546Z","iopub.execute_input":"2023-10-12T20:09:46.849058Z","iopub.status.idle":"2023-10-12T20:09:46.856327Z","shell.execute_reply.started":"2023-10-12T20:09:46.849012Z","shell.execute_reply":"2023-10-12T20:09:46.854817Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Create Datasets","metadata":{}},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels_encoded))\ntrain_dataset = train_dataset.map(preprocess_image)  # Apply preprocess_image function\ntrain_dataset = train_dataset.shuffle(buffer_size=len(train_images)).batch(32)\n\n# Create a dataset from tensors of test_images and test_labels\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels_encoded))\n\n# Apply the preprocess_image function to each sample in the test dataset\ntest_dataset = test_dataset.map(preprocess_image)\n\n# Create batches of size 32 for the test dataset\ntest_dataset = test_dataset.batch(32)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T20:09:46.858413Z","iopub.execute_input":"2023-10-12T20:09:46.858917Z","iopub.status.idle":"2023-10-12T20:09:46.870789Z","shell.execute_reply.started":"2023-10-12T20:09:46.858852Z","shell.execute_reply":"2023-10-12T20:09:46.869620Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Train the model","metadata":{}},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(train_dataset, epochs=10, validation_data=test_dataset)\n\n# Evaluate the model on the test dataset\nloss, accuracy = model.evaluate(test_dataset)\n\n# # Print the test loss and accuracy\n# # print(f\"Test Loss: {loss:.4f}\")\n# # print(f\"Test Accuracy: {accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-12T20:09:46.872838Z","iopub.execute_input":"2023-10-12T20:09:46.873339Z","iopub.status.idle":"2023-10-12T20:09:46.883614Z","shell.execute_reply.started":"2023-10-12T20:09:46.873298Z","shell.execute_reply":"2023-10-12T20:09:46.882543Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}